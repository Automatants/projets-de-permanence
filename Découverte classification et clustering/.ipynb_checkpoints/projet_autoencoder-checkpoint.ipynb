{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1frlG9I8sWZ"
   },
   "source": [
    "# Projet encadré : les auto-encodeurs\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Les auto-encodeurs sont une famille de réseaux de neurones particuliers qui ont pour premier objectif de réduire la dimension de l'espace des données qui nous intéressent. Il se décomposent en deux parties :\n",
    "\n",
    "*   Un encodeur qui doit apprendre la représantation des données d'entrée qui permet de passer de la dimension initiale à la dimension réduite.\n",
    "*   Un décodeur qui doit reproduire l'entrée le plus fidèlement possible à partir de la représentation que donne l'encodeur.\n",
    "\n",
    "On retrouve donc un structure caractéristique en \"goulot d'étranglement\" où les couches aux extrémités sont de la même dimension que la taille des données à caractériser et où la couche centrale est de la dimension de reduction souhaitée qui contiendra la représentation des entrées.\n",
    "\n",
    "![](https://www.researchgate.net/publication/318204554/figure/fig1/AS:512595149770752@1499223615487/Autoencoder-architecture.png)\n",
    "\n",
    "Pour entrainer ce réseau, on va seulement utilisée les données d'entrées : pas besoin donc de labéliser les données, on laisse la descente de gradient faire tout le travail : il s'agit d'un apprentissage non-supervisé.\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Sauf si vous utilisez Colab, il faudra importer les bibliothèques `numpy`, `tensorflow`, `keras` et `scikit-learn`\n",
    "\n",
    "# Première application : génération de nouvelles images\n",
    "\n",
    "Dans un premier temps on va essayer de générer des 5 à partir des données du MNIST. On va donc apprendre à notre réseau la représentation d'un 5 puis utiliser le décodeur pour fabriquer de nouveaux 5.\n",
    "\n",
    "## Création du réseau\n",
    "\n",
    "On va utiliser ce réseau sur le dataset MNIST (60000 chiffres en nuances de gris en 28x28). On règle la taille de l'espace latent (couche du milieu) avec la variable `latent_space_size` : plus la taille de cette couche est grande moins la réduction sera grande mais meuilleur sera la restitution de l'image par le décodeur.\n",
    "\n",
    "On créer d'abord l'auto-encodeur (encodeur + décodeur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGBy3HlW8rq1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# La dimension de l'image une fois compressée\n",
    "latent_space_size = 10\n",
    "\n",
    "# On définit les 2 couches de notre réseau (en plus de la couche d'entrée)\n",
    "encoder_layer = Dense(latent_space_size, activation='relu', input_dim=784)\n",
    "decoder_layer = Dense(784, activation='sigmoid', input_dim=latent_space_size)\n",
    "\n",
    "# On crée notre autoencoder\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(encoder_layer)\n",
    "autoencoder.add(decoder_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yG7Hf-Zm9UQd"
   },
   "source": [
    "On créé ensuite l'encodeur et le décodeur a partir des couches de l'auto-encodeur que l'on à définit précédément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qhx3H_f9UWr"
   },
   "outputs": [],
   "source": [
    "# L'encoder est composé seulement des 2 premieres couches\n",
    "encoder = Sequential()\n",
    "encoder.add(encoder_layer)\n",
    "\n",
    "# Le decoder est composé seulement des 2 dernières couches\n",
    "decoder = Sequential()\n",
    "decoder.add(decoder_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWN49tao9gx2"
   },
   "source": [
    "On va maintenant charger le dataset MNIST et seulement récuperer les 5. On normalise aussi les données : les nuances de gris des images du MNIST sont codées de 0 à 255 (0 pour le noir et 255 pour le blanc) que l'on va ramener sur l'intervalle [0;1]. Les réseaux de neurones \"classiques\" prennent en entrée des vecteurs, on va également convertir les images de 28x28 en vecteurs de taille 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFNlFNOG9gnA"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Le chiffre qu'on va utiliser pour l'entrainement de l'autoencoder\n",
    "digit = 7\n",
    "\n",
    "# On charge le dataset\n",
    "(complete_train_x, complete_train_y), (complete_test_x, complete_test_y) = mnist.load_data()\n",
    "\n",
    "\n",
    "# On récupere seulement les chiffres qui nous interessent\n",
    "digit_train_matrices = []\n",
    "digit_test_matrices = []\n",
    "\n",
    "for k in range(complete_train_y.shape[0]):\n",
    "    if complete_train_y[k] == digit:\n",
    "        digit_train_matrices.append(complete_train_x[k])\n",
    "\n",
    "for k in range(complete_test_y.shape[0]):\n",
    "    if complete_test_y[k] == digit:\n",
    "        digit_test_matrices.append(complete_test_x[k])\n",
    "\n",
    "restricted_train = np.zeros((len(digit_train_matrices), complete_train_x.shape[1], complete_train_x.shape[2]), dtype=float)\n",
    "restricted_test = np.zeros((len(digit_test_matrices), complete_test_x.shape[1], complete_test_x.shape[2]), dtype=float)\n",
    "\n",
    "# On normalise les données (les valeurs vont de 0 à 255, on les ramènes entre 0 et 1)\n",
    "for k in range(len(digit_train_matrices)):\n",
    "    restricted_train[k, :, :] = digit_train_matrices[k] / 255.0\n",
    "\n",
    "for k in range(len(digit_test_matrices)):\n",
    "    restricted_test[k, :, :] = digit_test_matrices[k] / 255.0\n",
    "\n",
    "# On change la dimension des images pour avoir un vecteur : 28*28 => 784\n",
    "restricted_train = restricted_train.reshape((restricted_train.shape[0], restricted_train.shape[1] * restricted_train.shape[2]))\n",
    "restricted_test = restricted_test.reshape((restricted_test.shape[0], restricted_test.shape[1] * restricted_test.shape[2]))\n",
    "    \n",
    "print(\"Dimension des données d'entrainement:\", restricted_train.shape)\n",
    "print(\"Dimension des données de test:\", restricted_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8zMHq0n-u2P"
   },
   "source": [
    "On donc 5421 images de 5 destinées a l'entrainement et 892 pour le test.\n",
    "\n",
    "On va à présent entrainer notre auto-encodeur pour qu'il fasse correspondre la sortie a l'entrée qu'on lui donne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2yspWYl-wle"
   },
   "outputs": [],
   "source": [
    "# On entraine le réseau avec pour une entrée donnée, une sortie identique attendue\n",
    "autoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "autoencoder.fit(restricted_train, restricted_train, epochs=200, batch_size=250, shuffle=True, validation_data=(restricted_test, restricted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Evr-zioP-9Bj"
   },
   "source": [
    "Une fois l'entrainement effectué, on va testé la qualité de l'auto-encodeur en vérifiant que les entrées ne sont pas trop déformées après sont passage dans le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0OxJBLG_02H"
   },
   "outputs": [],
   "source": [
    "# On décode puis réencode les images de test pour verifier l'efficacité de l'autoencoder\n",
    "encoded_images = encoder.predict(restricted_test)\n",
    "decoded_images = decoder.predict(encoded_images)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "# Fonction pour l'affichage : la premiere ligne avec les données réelles et la seconde après un passage dans le réseau\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "  display = random.randint(0, len(restricted_test))\n",
    "\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  \n",
    "  plt.imshow(restricted_test[display].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  \n",
    "  plt.imshow(decoded_images[display].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fbs4HkwnB-pi"
   },
   "source": [
    "## Génération de nouvelles images\n",
    "\n",
    "A présent on va récuperer le décodeur et à partir d'un vecteur de taille 25, générer une image de 5 en 28x28.\n",
    "En première approche, on peut essayer de passer des vecteurs aléatoires dans notre décodeur et espérer que l'image qui sorte ressemble à un 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gp7lV8xCBXf"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "# On génère des vecteurs aléatoires avec des valeurs entre 0 et 5 (arbitraire)\n",
    "random_vectors = (np.random.rand(n, latent_space_size)) * 5\n",
    "decoded_random_images = decoder.predict(random_vectors)\n",
    "\n",
    "# Affichage\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  \n",
    "  plt.imshow(decoded_random_images[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNu70J92Dh2i"
   },
   "source": [
    "Pas terrible... on peut deviner des formes de 5 aléatoires dans les images, mais ce n'est vraiment pas convainquant. En réalité les 25 coordonées du vecteur de l'espace latent sont corrélées, on ne peut donc pas mettre des valeurs complétement aléatoires. On va utiliser un algorithme linéaire afin de décorreler les variables de notre espace latent afin de s'assurer de générer des 5 qui sont \"dans la moyenne\"; il s'agit de l'algorithme PCA (analyse en composante principale, pour les matheux c'est pas très compliqué et on peut l'implémenter soit même, voir sur [wikipédia](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales)).\n",
    "\n",
    "La bibliothèque scikit-learn fourni déjà cette fonction. Cette algorithme nécéssite de connaitre les données à décoreler, on va donc passer toutes nos données d'entrées au travers de l'encodeur et voir comment les variables sont correlées entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrbP9OKUDntT"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# On créé des exemples qui vont êtres utilisés par le PCA\n",
    "samples_pca = encoder.predict(restricted_train)\n",
    "\n",
    "# On applique le PCA sur les données (pas de réduction de taille d'espace)\n",
    "pca = PCA(n_components=latent_space_size)\n",
    "pca.fit(samples_pca)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "# On génère des vecteurs aléatoires entre -2 et 2 (par rapport à l'ecart type)\n",
    "random_vectors = (np.random.rand(n, latent_space_size) - 0.5) * 15\n",
    "\n",
    "# On transforme les vecteurs en vecteurs valables pour l'espace latent\n",
    "random_vectors = pca.inverse_transform(random_vectors)\n",
    "decoded_random_images = decoder.predict(random_vectors)\n",
    "\n",
    "# Affichage\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  \n",
    "  plt.imshow(decoded_random_images[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdnVTkaXHWip"
   },
   "source": [
    "## Deuxième application : débruitage d'une image\n",
    "\n",
    "Une des application des application des auto-encodeurs est de supprimer le bruit sur les images.\n",
    "\n",
    "Voici quelques resultats auxquels on peut s'attendre (en haut l'image originale, au milieu, l'image bruitée et en bas l'image retrouvée par le réseau) :\n",
    "![](https://i.goopics.net/jXxOv.png)\n",
    "\n",
    "On va utiliser un réseau plus compliqué avec plusieurs couches de convolution (très efficace pour le traitement d'image) et des couches de pooling / up sampling au lieu des couches dense classique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2LyVFk5H9uL"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "\n",
    "# On définit la partie encoder de notre réseau\n",
    "encoder_layers = [\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same')\n",
    "]\n",
    "\n",
    "# On définit la partie decoder de notre réseau\n",
    "decoder_layers = [\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(7, 7, 32)),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "]\n",
    "\n",
    "\n",
    "    \n",
    "# On crée notre autoencoder\n",
    "autoencoder = Sequential()\n",
    "\n",
    "for k in range(len(encoder_layers)): \n",
    "  autoencoder.add(encoder_layers[k]) \n",
    "  \n",
    "for k in range(len(decoder_layers)): \n",
    "  autoencoder.add(decoder_layers[k])\n",
    "\n",
    "# On définit l'encoder\n",
    "encoder = Sequential()\n",
    "\n",
    "for k in range(len(encoder_layers)): \n",
    "  encoder.add(encoder_layers[k]) \n",
    "\n",
    "# On définit le decoder\n",
    "decoder = Sequential()\n",
    "\n",
    "for k in range(len(decoder_layers)): \n",
    "  decoder.add(decoder_layers[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qq0YfUUfR2aR"
   },
   "source": [
    "Cette fois on va utiliser le MNIST complet. Pour entrainer notre autoencodeur on va cette fois lui donner une image bruitée aléatoirment en entrée et lui de mander de sortir l'image non bruitée en sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Y5xOCxqR4n-"
   },
   "outputs": [],
   "source": [
    "# Chargement du MNIST complet\n",
    "(complete_train_x, _), (complete_test_x, _) = mnist.load_data()\n",
    "\n",
    "complete_train_x = complete_train_x.astype('float32') / 255.0\n",
    "complete_train_x = np.reshape(complete_train_x, (len(complete_train_x), 28, 28, 1))\n",
    "\n",
    "complete_test_x = complete_test_x.astype('float32') / 255.0\n",
    "complete_test_x = np.reshape(complete_test_x, (len(complete_test_x), 28, 28, 1))\n",
    "\n",
    "# On ajoute du bruit sur l'image\n",
    "noise_factor = 0.5\n",
    "\n",
    "noise_train_set = complete_train_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=complete_train_x.shape)\n",
    "noise_train_set = np.clip(noise_train_set, 0.0, 1.0)\n",
    "\n",
    "noise_test_set = complete_test_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=complete_test_x.shape)\n",
    "noise_test_set = np.clip(noise_test_set, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYUN00OgSsaQ"
   },
   "source": [
    "On peut changer la quantité de bruit sur l'image en changeant noise factor. Le réseau sera encore capable de fournir des resultats satisfaisant pour noise factor allant jusqu'a 0.9.\n",
    "\n",
    "Conseil : pour entrainer ce reseau la, il vaut mieux reprendre le code en local si vous ne voulez pas attendre 4h (ou diminuez le nombre d'epochs mais les resultats seront moins bon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmK714r4StLm"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(noise_train_set, complete_train_x, epochs=100, batch_size=128, shuffle=True, validation_data=(noise_test_set, complete_test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvJkoEFmWz7A"
   },
   "source": [
    "Maintenant, il suffit de montrer une image de chiffre bruitée au réseau pour qu'il retire le bruit sans trop deformer l'image originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lg02eYTyWzBX"
   },
   "outputs": [],
   "source": [
    "# On passe notre image bruitée dans l'autoencoder\n",
    "denoised_images = autoencoder.predict(noise_test_set)\n",
    "\n",
    "# Fonction pour l'affichage : la premiere ligne avec les données réelles et la seconde après un passage dans le réseau\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "  display = random.randint(0, len(complete_test_x))\n",
    "  \n",
    "  ax = plt.subplot(3, n, i + 1)\n",
    "  \n",
    "  plt.imshow(complete_test_x[display].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  ax = plt.subplot(3, n, i + 1 + n)\n",
    "  \n",
    "  plt.imshow(noise_test_set[display].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "  \n",
    "  plt.imshow(denoised_images[display].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  \n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iktGD6VJPvtj"
   },
   "source": [
    "\n",
    "# Partie pratique, a vous de jouer !!\n",
    "\n",
    "\n",
    " Maintenant que l'on a fait mumuse avec des chiffres manuscrits, il est temps pour vous de manipuler ! Pour cela voici un nouveau dataset contenant des vetements: le fashion_mnist !\n",
    " \n",
    "La classification est :\n",
    "\n",
    "* 0 T-shirts\n",
    "* 1 Pantalongs\n",
    "* 2 Pulls\n",
    "* 3 Robes\n",
    "* 4 Manteaux\n",
    "* 5 Sandalles\n",
    "* 6 Chemises\n",
    "* 7 Sneakers\n",
    "* 8 Sacs\n",
    "* 9 Chassures à talons\n",
    "\n",
    "A vous de retravailler l'exemple précédent avec ces nouvelles données pour générer des chassures de tout type (sneaker, sandalles, talons), et pouvoir les débruiter !\n",
    "\n",
    "Pour cela, ne prenez pas les chiffres de l'exemple pour aquis ! C'est un nouveau problème et il vous incombe de créer et modifier votre Auto-Encoder de manière a ce que cela fonctionne !\n",
    "\n",
    "Have fun !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ETghi1gPyrv"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Charge le dataset fashion_mnist\n",
    "(complete_train_x, complete_train_y), (complete_test_x, complete_test_y) = fashion_mnist.load_data()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
